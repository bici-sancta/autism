---
title: "autism"
author: "mcdevitt"
date: "03 avr 2017"
output:
  html_document:
    highlight: tango
    theme: united
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Homework 11 - Problem Set 2 - Autism Prevalence

```{r autism}

home_dir <- "~/_smu/_src/autism/"
setwd(home_dir)
data_dir <- "./data"
setwd(data_dir)

s29 <- read.csv("ex0829.csv", stringsAsFactors = FALSE)

setwd(home_dir)

plot(s29$Prevalence ~ s29$Year)

# ... define data set to analyze 

s29$x2 <- (s29$Year - 1992) * (s29$Year - 1992)

df_xy <- data.frame(s29$Year, s29$Prevalence, s29$x2)

names(df_xy) <- c("xxx", "yyy", "x2")

str(df_xy)

```

#### __scatter plot of the data shows general trend to be parabolic. Expect that linear fit is not appropriate for this data set. Have expectation that model in X^2 is likely a better fit. In any case, run the basic linear model on the raw data set to evaluate the results.__  

=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=--=-=-=-  
### __i. A Scatterplot with confidence intervals of the regression line and prediction intervals of the regression line.__    
=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=--=-=-=-  

```{r, echo = FALSE}


fit_all <- lm(yyy ~ xxx, data = df_xy)

df_xy_conf_int <- as.data.frame(predict(fit_all, df_xy , interval = "confidence"))

plot(df_xy$yyy ~ df_xy$xxx, col = 'blue', pch = 19)
polygon(c(df_xy$xxx, rev(df_xy$xxx)),
		c(df_xy_conf_int$lwr, rev(df_xy_conf_int$upr)),col="lightgrey")

lines(fit_all$fitted.values ~ df_xy$xxx, col = 'black', lwd = 4, lty = 3)

lines(df_xy_conf_int$lwr ~ df_xy$xxx, col = 'black', lwd = 1)
lines(df_xy_conf_int$upr ~ df_xy$xxx, col = 'black', lwd = 1)

points(df_xy$yyy ~ df_xy$xxx, col = 'blue', pch = 19)

df_xy_pred_int <- as.data.frame(predict(fit_all, df_xy, interval = "predict"))

lines(df_xy_pred_int$lwr ~ df_xy$xxx, col = 'grey', lwd = 1, lty = 2)
lines(df_xy_pred_int$upr ~ df_xy$xxx, col = 'grey', lwd = 1, lty = 2)

```

  
=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=--=-=-=-  
__ii. A table showing the t-statistics and pvalues for the significance of the regression parameters: .__  
=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=--=-=-=-  

```{r plot, echo=FALSE}

summary(fit_all)

```


=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=--=-=-=-  
### __iv. The regression equation.__    
=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=--=-=-=-  


``` {r, echo = FALSE}

b0 <- fit_all$coefficients[1]
b1 <- fit_all$coefficients[2]

```

The Regression equation : 
* yyy = `r b1` * xxx + `r b0`


=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=--=-=-=-  
__x. A scatterplot of residuals.__  
=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=--=-=-=-  


``` {r, echo = FALSE}

yyy_res = resid(fit_all)

plot(df_xy$xxx, yyy_res, 
     pch = 19,
	 col = "blue",
	 xlab="", 
     main="Autism Prevalence- Residual Plot") 
abline(0, 0)

```


### --> As expected, the plot of residuals vs predicted values shows a non-random distribution. This demonstrates that the basic assumption of linearity for the model is not supported by the data set. Need to evaluate if data transformation model can provide a more appropriate fit for this data set. Since the Autism Prevalence rate visually appears to  vary at the square of the year increase, a model based on (Year - 1992)^2 will be fit, using the base year (1992) as a reference year for the rest of the study period.  

=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=--=-=-=-  


#### b. Second Model ---- Autism = b0 + b1 * (Year-1992)^2    

=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=--=-=-=-  
=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=--=-=-=-  

### __i. A Scatterplot with confidence intervals of the regression line and prediction intervals of the regression line.__  


```{r, echo = FALSE}

df_xy$xxx <- df_xy$x2

fit_all <- lm(yyy ~ xxx, data = df_xy)

df_xy_conf_int <- as.data.frame(predict(fit_all, df_xy , interval = "confidence"))

plot(df_xy$yyy ~ df_xy$xxx, col = 'blue', pch = 19)
polygon(c(df_xy$xxx, rev(df_xy$xxx)),
		c(df_xy_conf_int$lwr, rev(df_xy_conf_int$upr)),col="lightgrey")

lines(fit_all$fitted.values ~ df_xy$xxx, col = 'black', lwd = 4, lty = 3)

lines(df_xy_conf_int$lwr ~ df_xy$xxx, col = 'black', lwd = 1)
lines(df_xy_conf_int$upr ~ df_xy$xxx, col = 'black', lwd = 1)

points(df_xy$yyy ~ df_xy$xxx, col = 'blue', pch = 19)

df_xy_pred_int <- as.data.frame(predict(fit_all, df_xy, interval = "predict"))

lines(df_xy_pred_int$lwr ~ df_xy$xxx, col = 'grey', lwd = 1, lty = 2)
lines(df_xy_pred_int$upr ~ df_xy$xxx, col = 'grey', lwd = 1, lty = 2)

```

  
=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=--=-=-=-  
### __ii. A table showing the t-statistics and pvalues for the significance of the regression parameters: .   Please do in SAS and R!__  
=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=--=-=-=-  


```{r, echo=FALSE}

summary(fit_all)

```


=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=--=-=-=-  
### __iii. Using the data in ii show all 6 steps of each hypothesis test.__   
=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=--=-=-=-  

##### __Six-Step Hypothesis Test - Slope__   

``` {r, echo = FALSE}

alpha <- 0.05
dof <- dim(df_xy)[1] - 2
crit_value <- qt(1 - alpha/2, dim(df_xy)[1] - 2)

t_value <- coef(summary(fit_all))["xxx","t value"]
p_value <- coef(summary(fit_all))["xxx","Pr(>|t|)"]

if (p_value < alpha)
{
	acc_rej <- "Reject Ho"
	is_is_not_1 <- "is"
	is_is_not_2 <- "is not"
	does_does_not <- "does not"
} else {
	acc_rej <- "Do not Reject Ho"
	is_is_not_1 <- "is not"
	is_is_not_2 <- "is"
	does_does_not <- "does"
}

cnf_intrvl <- confint(fit_all, 'xxx', level = 1 - alpha)
cnf_intrvl_lwr <- cnf_intrvl[1,1]
cnf_intrvl_upr <- cnf_intrvl[1,2]

print_cnf_intrvl <- paste0(sprintf("(%9.3f", cnf_intrvl_lwr), sprintf(", %9.3f)", cnf_intrvl_upr))

```

1: Ho : b1 = 0; Ha ; b1 != 0  

2 : Critical Value : t(0.975, df = __`r dof `__) = +/- __`r crit_value`__   

3 : t = `r t_value `    

4 : p_value = `r p_value` < 0.05 ?    

5: `r acc_rej`  

6 : There `r is_is_not_1` sufficient evidence to suggest at the alpha = `r alpha` level of significance (p-value = `r p_value`) that the slope of the regression line that estimates the increase in Autism Prevalence as a function of (Year-1992)^2 `r is_is_not_2` equal to zero. A `r (1 - alpha)*100`% confidence interval for the slope is `r print_cnf_intrvl`, which is an interval that `r does_does_not` contain the value zero  
  

##### __Six-Step Hypothesis Test - Intercept__   

``` {r, echo = FALSE}

alpha <- 0.05
dof <- dim(df_xy)[1] - 2
crit_value <- qt(1 - alpha/2, dim(df_xy)[1] - 2)

t_value <- coef(summary(fit_all))["(Intercept)","t value"]
p_value <- coef(summary(fit_all))["(Intercept)","Pr(>|t|)"]

if (p_value < alpha)
{
	acc_rej <- "Reject Ho"
	is_is_not <- "is"
	does_does_not <- "does not"
} else {
	acc_rej <- "Do not Reject Ho"
	is_is_not <- "is not"
	does_does_not <- "does"
}

cnf_intrvl <- confint(fit_all, '(Intercept)', level = 1 - alpha)
cnf_intrvl_lwr <- cnf_intrvl[1,1]
cnf_intrvl_upr <- cnf_intrvl[1,2]

print_cnf_intrvl <- paste0(sprintf("(%9.3f", cnf_intrvl_lwr), sprintf(", %9.3f)", cnf_intrvl_upr))

```

1 : Ho : b0 = 0; Ha ; b0 != 0  

2 : Critical Value : t(0.975, df = __`r dof `__) = +/- __`r crit_value`__   

3 : t = `r t_value `    

4 : p_value = `r p_value` < 0.05 ?    

5: `r acc_rej`  

6 : There `r is_is_not_1` sufficient evidence to suggest at the alpha = `r alpha` level of significance (p-value = `r p_value`) that the intercept of the regression line that estimates the increase in Autism Prevalence as a function of (Year-1992)^2 `r is_is_not_2` equal to zero. A `r (1 - alpha)*100`% confidence interval for the slope is `r print_cnf_intrvl`, which is an interval that `r does_does_not` contain the value zero  
  


=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=--=-=-=-  
__iv. The regression equation.__    


``` {r, echo = FALSE}

b0 <- fit_all$coefficients[1]
b1 <- fit_all$coefficients[2]

```

###The Regression equation : 
#### Autism Prevalence = `r b1` * (Year - 1992)^2 + `r b0`


=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=--=-=-=-  
### __v. Interpretation of the slope and intercept in the model (regression equation.)__   
=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=--=-=-=-  

##### __The slope represents the rate of change [per (year-reference year of 1992)^2 ] in autism per 10,000 10-year-old US children for the five-year period of the study. In other words, for each succeeding year after 1992 (refernce year) the autism prevalence increases as a function of (year-1992)^2. __  
  
#### __The intercept in this case is simply the model (expected) level of Autism Prevalence in the Reference Year of 1992, (Year 0) for this model. In this case, the model's value = `r b0`__  

=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=--=-=-=-  
__x. A scatterplot of residuals.__  

``` {r, echo = FALSE}

yyy_res = resid(fit_all)

plot(df_xy$xxx, yyy_res, 
     pch = 19,
	 col = "blue",
	 ylab="Residuals",
	 xlab="", 
     main="Autism Prevalance - Residual Plot") 
abline(0, 0)

```

=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=--=-=-=-  
### __xi. A histogram of residuals with normal distribution superimposed.__    
=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=--=-=-=-  


``` {r, echo = FALSE}

res_mean <- mean(yyy_res)
res_std <- sqrt(var(yyy_res))

hist(yyy_res, density=20, breaks = 10, prob = TRUE, 
     xlab="",
#	 ylim=c(0, 10), 
     main="Autism Prevalence - Residuals")

curve(dnorm(x, mean = res_mean, sd = res_std),
	  col = "darkblue",
	  lwd = 2,
	  add = TRUE,
	  yaxt = "n")

```


=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=--=-=-=-  
### __xii. Provide a measure of the amount of variation in the response that is accounted for by the explanatory variable.  Interpret this measure clearly indicating the units of the response and the explanatory variables.__  
=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=--=-=-=-  


```{r}
r2 <- summary.lm(fit_all, r.squared=TRUE)$r.squared
r2_format <- sprintf("%8.2f %%", r2*100)
non_r2_format <- sprintf("%8.2f %%", (1.0 - r2)*100)
```

#### R-squared value for model = `r r2`

#### Therefore, `r r2_format` of the variation observed in the dependent variable (Autism Prevalence) is explained by the increasing yearly count (with 1992 as the reference year) independent variable, leaving only `r non_r2_format` variation that is available to be explained by any remaining contributory factors.


=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=--=-=-=-  
end-of-document  
=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=--=-=-=-  
